{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "wSvXscCti72W"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from IPython.display import display\n",
    "from sklearn import tree\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import linear_model\n",
    "import joblib \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "q-TDreEVmzzQ"
   },
   "outputs": [],
   "source": [
    "#Original Dataset\n",
    "conn = sqlite3.connect('fpa_archive/FPA_FOD_20170508.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Np9ue-RtrNjQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM fires;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acDMFryLsC1X",
    "outputId": "c5d3b287-422a-4cc4-b6c9-d33c69a194e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OBJECTID  FOD_ID      FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
      "5000       5001    5024  FS-1428631                FED   FS-FIRESTAT   \n",
      "5010       5011    5034  FS-1428644                FED   FS-FIRESTAT   \n",
      "5020       5021    5044  FS-1428657                FED   FS-FIRESTAT   \n",
      "5030       5031    5054  FS-1428673                FED   FS-FIRESTAT   \n",
      "5040       5041    5064  FS-1428687                FED   FS-FIRESTAT   \n",
      "...         ...     ...         ...                ...           ...   \n",
      "49950     49951   50294   FS-270902                FED   FS-FIRESTAT   \n",
      "49960     49961   50305   FS-270916                FED   FS-FIRESTAT   \n",
      "49970     49971   50315   FS-270950                FED   FS-FIRESTAT   \n",
      "49980     49981   50325   FS-270960                FED   FS-FIRESTAT   \n",
      "49990     49991   50335   FS-270970                FED   FS-FIRESTAT   \n",
      "\n",
      "      NWCG_REPORTING_AGENCY NWCG_REPORTING_UNIT_ID  \\\n",
      "5000                     FS                USAZKNF   \n",
      "5010                     FS                USAZKNF   \n",
      "5020                     FS                USFLFNF   \n",
      "5030                     FS                USCATMU   \n",
      "5040                     FS                USAZCOF   \n",
      "...                     ...                    ...   \n",
      "49950                    FS                USORFWF   \n",
      "49960                    FS                USORFWF   \n",
      "49970                    FS                USORFWF   \n",
      "49980                    FS                USORFWF   \n",
      "49990                    FS                USORFWF   \n",
      "\n",
      "               NWCG_REPORTING_UNIT_NAME SOURCE_REPORTING_UNIT  \\\n",
      "5000             Kaibab National Forest                  0307   \n",
      "5010             Kaibab National Forest                  0307   \n",
      "5020        National Forests in Florida                  0805   \n",
      "5030   Lake Tahoe Basin Management Unit                  0519   \n",
      "5040           Coconino National Forest                  0304   \n",
      "...                                 ...                   ...   \n",
      "49950    Fremont-Winema National Forest                  0602   \n",
      "49960    Fremont-Winema National Forest                  0602   \n",
      "49970    Fremont-Winema National Forest                  0602   \n",
      "49980    Fremont-Winema National Forest                  0602   \n",
      "49990    Fremont-Winema National Forest                  0602   \n",
      "\n",
      "             SOURCE_REPORTING_UNIT_NAME  ... FIRE_SIZE   LATITUDE   LONGITUDE  \\\n",
      "5000             Kaibab National Forest  ...       0.1  36.728611 -112.123611   \n",
      "5010             Kaibab National Forest  ...       0.1  36.507222 -112.185000   \n",
      "5020        National Forests in Florida  ...       1.2  30.358333  -84.375000   \n",
      "5030   Lake Tahoe Basin Management Unit  ...       0.1  38.940000 -120.046667   \n",
      "5040           Coconino National Forest  ...       0.1  35.273333 -111.745000   \n",
      "...                                 ...  ...       ...        ...         ...   \n",
      "49950    Fremont-Winema National Forest  ...       0.1  42.376667 -120.403333   \n",
      "49960    Fremont-Winema National Forest  ...       0.1  42.493333 -120.695000   \n",
      "49970    Fremont-Winema National Forest  ...       0.1  42.551667 -120.735000   \n",
      "49980    Fremont-Winema National Forest  ...       0.1  43.275000 -121.201667   \n",
      "49990    Fremont-Winema National Forest  ...       0.1  43.288333 -121.201667   \n",
      "\n",
      "      OWNER_CODE       OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME  \\\n",
      "5000         5.0              USFS    AZ      5       005  Coconino   \n",
      "5010         5.0              USFS    AZ      5       005  Coconino   \n",
      "5020        13.0  STATE OR PRIVATE    FL   None      None      None   \n",
      "5030         5.0              USFS    CA     61       061    Placer   \n",
      "5040         5.0              USFS    AZ      5       005  Coconino   \n",
      "...          ...               ...   ...    ...       ...       ...   \n",
      "49950        5.0              USFS    OR   None      None      None   \n",
      "49960        5.0              USFS    OR   None      None      None   \n",
      "49970        5.0              USFS    OR   None      None      None   \n",
      "49980        5.0              USFS    OR   None      None      None   \n",
      "49990        5.0              USFS    OR   None      None      None   \n",
      "\n",
      "                                                   Shape  \n",
      "5000   b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\xb7\\x92>\\xe9\\x0...  \n",
      "5010   b'\\x00\\x01\\xad\\x10\\x00\\x00\\xa0p=\\n\\xd7\\x0b\\\\\\x...  \n",
      "5020   b'\\x00\\x01\\xad\\x10\\x00\\x00\\xfc\\xff\\xff\\xff\\xff...  \n",
      "5030   b'\\x00\\x01\\xad\\x10\\x00\\x00\\xa4]3\\x96\\xfc\\x02^\\...  \n",
      "5040   b'\\x00\\x01\\xad\\x10\\x00\\x00D\\xe1z\\x14\\xae\\xef[\\...  \n",
      "...                                                  ...  \n",
      "49950  b'\\x00\\x01\\xad\\x10\\x00\\x00$o\\x996\\xd0\\x19^\\xc0...  \n",
      "49960  b'\\x00\\x01\\xad\\x10\\x00\\x00\\x14\\xaeG\\xe1z,^\\xc0...  \n",
      "49970  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd4\\xa3p=\\n/^\\xc0\\x...  \n",
      "49980  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xf4\\x15R\\x1b\\xe8L^\\...  \n",
      "49990  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xf4\\x15R\\x1b\\xe8L^\\...  \n",
      "\n",
      "[4500 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "#Taking random 4500 rows of the entire datset to get their fire size class prediction, We can take any number of rows from any part of the data for getting the result\n",
    "dataset = df[5000:50000:10]\n",
    "dataset_func1 = dataset.drop(['FIRE_SIZE_CLASS'], axis = 1)\n",
    "print(dataset_func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n",
       "       'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID',\n",
       "       'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT',\n",
       "       'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID',\n",
       "       'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME',\n",
       "       'ICS_209_INCIDENT_NUMBER', 'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME',\n",
       "       'COMPLEX_NAME', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_DOY',\n",
       "       'DISCOVERY_TIME', 'STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR', 'CONT_DATE',\n",
       "       'CONT_DOY', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE',\n",
       "       'LONGITUDE', 'OWNER_CODE', 'OWNER_DESCR', 'STATE', 'COUNTY',\n",
       "       'FIPS_CODE', 'FIPS_NAME', 'Shape'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x01\\xad\\x10\\x00\\x00\\xa0p=\\n\\xd7\\x0b\\\\\\xc08Z_\\xa8\\xec@B@\\xa0p=\\n\\xd7\\x0b\\\\\\xc08Z_\\xa8\\xec@B@|\\x01\\x00\\x00\\x00\\xa0p=\\n\\xd7\\x0b\\\\\\xc08Z_\\xa8\\xec@B@\\xfe'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[1].Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dataset.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OBJECTID                                                                   5021\n",
       "FOD_ID                                                                     5044\n",
       "FPA_ID                                                               FS-1428657\n",
       "SOURCE_SYSTEM_TYPE                                                          FED\n",
       "SOURCE_SYSTEM                                                       FS-FIRESTAT\n",
       "NWCG_REPORTING_AGENCY                                                        FS\n",
       "NWCG_REPORTING_UNIT_ID                                                  USFLFNF\n",
       "NWCG_REPORTING_UNIT_NAME                            National Forests in Florida\n",
       "SOURCE_REPORTING_UNIT                                                      0805\n",
       "SOURCE_REPORTING_UNIT_NAME                          National Forests in Florida\n",
       "LOCAL_FIRE_REPORT_ID                                                         60\n",
       "LOCAL_INCIDENT_ID                                                            15\n",
       "FIRE_CODE                                                                  B7WA\n",
       "FIRE_NAME                                                                WALNUT\n",
       "ICS_209_INCIDENT_NUMBER                                                    None\n",
       "ICS_209_NAME                                                               None\n",
       "MTBS_ID                                                                    None\n",
       "MTBS_FIRE_NAME                                                             None\n",
       "COMPLEX_NAME                                                               None\n",
       "FIRE_YEAR                                                                  2005\n",
       "DISCOVERY_DATE                                                        2453698.5\n",
       "DISCOVERY_DOY                                                               328\n",
       "DISCOVERY_TIME                                                             1500\n",
       "STAT_CAUSE_CODE                                                             5.0\n",
       "STAT_CAUSE_DESCR                                                 Debris Burning\n",
       "CONT_DATE                                                             2453698.5\n",
       "CONT_DOY                                                                  328.0\n",
       "CONT_TIME                                                                  1600\n",
       "FIRE_SIZE                                                                   1.2\n",
       "FIRE_SIZE_CLASS                                                               B\n",
       "LATITUDE                                                              30.358333\n",
       "LONGITUDE                                                               -84.375\n",
       "OWNER_CODE                                                                 13.0\n",
       "OWNER_DESCR                                                    STATE OR PRIVATE\n",
       "STATE                                                                        FL\n",
       "COUNTY                                                                     None\n",
       "FIPS_CODE                                                                  None\n",
       "FIPS_NAME                                                                  None\n",
       "Shape                         b'\\x00\\x01\\xad\\x10\\x00\\x00\\xfc\\xff\\xff\\xff\\xff...\n",
       "Name: 5020, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx =dfx.drop(['FIRE_SIZE_CLASS'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 38)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "brdojqp7iLez"
   },
   "outputs": [],
   "source": [
    "def DataPrediction(data):\n",
    "  test_df = pd.DataFrame() \n",
    "  for i in range(3):\n",
    "    SampleModel = joblib.load('pickle/SampleModel_'+ str(i) + '.pkl')\n",
    "    predictedValues = SampleModel.predict(data)\n",
    "    columnName = 'predict' + str(i)\n",
    "    test_df[columnName] = predictedValues\n",
    "\n",
    "  test_finalPrediction = []\n",
    "  for j in range(len(test_df)):\n",
    "    row_list = test_df.iloc[j].values.tolist()\n",
    "    majority_count = max(set(row_list) , key=row_list.count)\n",
    "    test_finalPrediction.append(majority_count)\n",
    "\n",
    "  test_finalPrediction = np.array(test_finalPrediction)\n",
    "  return(test_finalPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "giux5mqyj9NI"
   },
   "outputs": [],
   "source": [
    "def function1(data):\n",
    "  '''This function will give the prediction for input data given'''\n",
    "\n",
    "  print('Deleting unnecessary features......\\n')\n",
    "  del_features = ['OBJECTID', 'FOD_ID', 'FPA_ID', 'NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT', 'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID', 'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME', 'ICS_209_INCIDENT_NUMBER' , 'ICS_209_NAME', 'MTBS_FIRE_NAME', 'MTBS_ID', 'COMPLEX_NAME', 'DISCOVERY_DATE', 'STAT_CAUSE_DESCR', 'CONT_DATE', 'CONT_TIME', 'FIRE_SIZE', 'OWNER_DESCR', 'COUNTY', 'FIPS_CODE', 'FIPS_NAME', 'Shape' ]\n",
    "  for i, item in enumerate(del_features):\n",
    "    del data[item];\n",
    "  print('Data shape is: ', data.shape, '\\n')\n",
    "\n",
    "  print('Encoding features......\\n')\n",
    "  label_encoder = preprocessing.LabelEncoder() \n",
    "  encode_features = ['SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM', 'NWCG_REPORTING_AGENCY']\n",
    "  for j, e_item in enumerate(encode_features):\n",
    "    data[e_item] = label_encoder.fit_transform(data[e_item]) \n",
    "    data[e_item].astype('int64')\n",
    "\n",
    "  #Manually encoding states feature\n",
    "  data['STATE'] = data['STATE'].map({'AL': 0, 'AK': 1, 'AZ': 2, 'AR': 3, 'CA': 4, 'CO': 5,'CT': 6,'DE': 7,'DC': 8,'FL': 9,'GA': 10,'HI': 11,'ID': 12,'IL': 13,'IN': 14,'IA': 15,'KS': 16,'KY': 17,'LA': 18,'ME': 19,'MD': 20,'MA': 21,'MI': 22,'MN': 23,'MS': 24,'MO': 25,'MT': 26,'NE': 27,'NV': 28,'NH': 29,'NJ': 30,'NM': 31,'NY': 32,'NC': 33,'ND': 34,'OH': 35,'OK': 36,'OR': 37,'PA': 38,'PR': 39,'RI': 40,'SC': 41,'SD': 42,'TN': 43,'TX': 44,'UT': 45,'VT': 46,'VA': 47,'WA': 48,'WV': 49,'WI': 50,'WY': 51}) \n",
    "  data['STATE'].astype('int64')\n",
    "\n",
    "  print('Performing Feature Engineering......\\n')\n",
    "  #Adding Feature Discovery Month\n",
    "  discovery_month = [];\n",
    "  for i in range(len(data)):\n",
    "   key = data.iloc[i]['DISCOVERY_DOY']\n",
    "   if( 1 <= key <= 31 ):\n",
    "    discovery_month.append(1)\n",
    "   elif ( 32 <= key <= 60 ):\n",
    "      discovery_month.append(2)\n",
    "   elif ( 61 <= key <= 91 ):\n",
    "     discovery_month.append(3)\n",
    "   elif ( 92 <= key <= 121 ):\n",
    "     discovery_month.append(4)\n",
    "   elif ( 122 <= key <= 152 ):\n",
    "     discovery_month.append(5)\n",
    "   elif ( 153 <= key <= 182 ):\n",
    "     discovery_month.append(6)\n",
    "   elif ( 183 <= key <= 213 ):\n",
    "     discovery_month.append(7)\n",
    "   elif ( 214 <= key <= 244 ):\n",
    "     discovery_month.append(8)\n",
    "   elif ( 245 <= key <= 274 ):\n",
    "     discovery_month.append(9)\n",
    "   elif ( 275 <= key <= 305 ):\n",
    "     discovery_month.append(10)\n",
    "   elif ( 306 <= key <= 335 ):\n",
    "     discovery_month.append(11)\n",
    "   elif ( 336 <= key <= 366 ):\n",
    "     discovery_month.append(12)\n",
    "    \n",
    "  data['DISCOVERY_MONTH'] = discovery_month\n",
    "  data['DISCOVERY_MONTH'].astype('int64')\n",
    "  print('Data shape is: ', data.shape, '\\n')\n",
    "\n",
    "  #Delete DISCOVERY_DOY and CONT_DOY also now\n",
    "  del data['DISCOVERY_DOY']\n",
    "  del data['CONT_DOY']\n",
    "\n",
    "  #Feature2 DISCOVERY_TOD\n",
    "  discovery_tod = [];\n",
    "  data['DISCOVERY_TIME'] = data['DISCOVERY_TIME'].replace([None],'0000')\n",
    "  for i in range(len(data)):\n",
    "    key = data.iloc[i]['DISCOVERY_TIME']\n",
    "    if( key == '0000' ):\n",
    "      discovery_tod.append(0)\n",
    "    elif ( '0000' < key <= '0600' ):\n",
    "      discovery_tod.append(1)\n",
    "    elif ( '0600' < key <= '1200' ):\n",
    "      discovery_tod.append(2)\n",
    "    elif ( '1200' < key <= '1600' ):\n",
    "      discovery_tod.append(3)\n",
    "    elif ( '1600' < key <= '2000' ):\n",
    "      discovery_tod.append(4)\n",
    "    elif ( '2000' < key <= '2400' ):\n",
    "      discovery_tod.append(5)\n",
    "\n",
    "  data['DISCOVERY_TOD'] = discovery_tod\n",
    "  data['DISCOVERY_TOD'].astype('int64')\n",
    "\n",
    "  del data['DISCOVERY_TIME']\n",
    "\n",
    "  data['LATITUDE'] = (data['LATITUDE']*10).apply(np.floor)/10\n",
    "  data['LONGITUDE'] = (data['LONGITUDE']*10).apply(np.floor)/10\n",
    "\n",
    "  #Add forest Area feature\n",
    "  forest_Area = pd.read_excel('xlsx/FOREST_Area.xlsx')\n",
    "  forest_Area.head()\n",
    "  STATE_PRCNT_FOREST = [];\n",
    "  for i in range(len(data)):\n",
    "    key = data.iloc[i]['STATE'].astype('int64')\n",
    "    STATE_PRCNT_FOREST.append(forest_Area['Forest_Coverage'].values[key])\n",
    "  \n",
    "  data['STATE_PRCNT_FOREST'] = STATE_PRCNT_FOREST\n",
    "  data['STATE_PRCNT_FOREST'].astype('float64')\n",
    "\n",
    "  #Add Avg Temp Feature\n",
    "  avg_temp  = pd.read_excel('xlsx/avg_temp.xlsx')\n",
    "\n",
    "  AVG_TEMP_LIST = [];\n",
    "  for i in range(len(data)):\n",
    "    state_key = data.iloc[i]['STATE'].astype('int64')\n",
    "    year_key = data.iloc[i]['FIRE_YEAR'].astype('int64')\n",
    "    AVG_TEMP_LIST.append(avg_temp[year_key].values[state_key])\n",
    "  \n",
    "  data['AVG_TEMP'] = AVG_TEMP_LIST\n",
    "  data['AVG_TEMP'].astype('float64')\n",
    "\n",
    "  #Add Avg Prec Feature\n",
    "  avg_prec  = pd.read_excel('xlsx/avg_prec.xlsx')\n",
    "\n",
    "  AVG_PREC_LIST = [];\n",
    "  for i in range(len(data)):\n",
    "   state_key = data.iloc[i]['STATE'].astype('int64')\n",
    "   AVG_PREC_LIST.append(avg_prec['Avg_Prec'].values[state_key])\n",
    "\n",
    "  data['AVG_PREC'] = AVG_PREC_LIST\n",
    "  data['AVG_PREC'].astype('float64')\n",
    "  print('Final features are: ', data.columns,'\\n')\n",
    "  print('EDA Completed...... \\n')\n",
    "  print('Predicting the fire size class......\\n')\n",
    "\n",
    "  predictions = DataPrediction(data)\n",
    "  data['PREDICTED_CLASS'] = predictions\n",
    "  #Simplifying the predicted class by giving area covered in each class\n",
    "  predictedRange = []\n",
    "  for i in range(len(data)):\n",
    "    key = data.iloc[i]['PREDICTED_CLASS']\n",
    "    if( key == 1 ):\n",
    "      predictedRange.append('0-0.25 acres')\n",
    "    elif ( key == 2 ):\n",
    "      predictedRange.append('0.26-9.9 acres')\n",
    "    elif ( key == 3 ):\n",
    "      predictedRange.append('10.0-99.9 acres')\n",
    "    elif ( key == 4 ):\n",
    "      predictedRange.append('100-299 acres')\n",
    "    elif ( key == 5 ):\n",
    "      predictedRange.append('300-999 acres')\n",
    "    elif ( key == 6 ):\n",
    "      predictedRange.append('1000-5000 acres')\n",
    "    else:\n",
    "      predictedRange.append('5000+ acres')\n",
    "    \n",
    "  data['Area Range'] = predictedRange\n",
    "  print(data.columns)\n",
    "  print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W62ObGNOkk3H",
    "outputId": "9a3ecc9f-46d4-4a26-8798-8beff8b3bc29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting unnecessary features......\n",
      "\n",
      "Data shape is:  (2, 12) \n",
      "\n",
      "Encoding features......\n",
      "\n",
      "Performing Feature Engineering......\n",
      "\n",
      "Data shape is:  (2, 13) \n",
      "\n",
      "Final features are:  Index(['SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM', 'NWCG_REPORTING_AGENCY',\n",
      "       'FIRE_YEAR', 'STAT_CAUSE_CODE', 'LATITUDE', 'LONGITUDE', 'OWNER_CODE',\n",
      "       'STATE', 'DISCOVERY_MONTH', 'DISCOVERY_TOD', 'STATE_PRCNT_FOREST',\n",
      "       'AVG_TEMP', 'AVG_PREC'],\n",
      "      dtype='object') \n",
      "\n",
      "EDA Completed...... \n",
      "\n",
      "Predicting the fire size class......\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    0.0s finished\n",
      "Index(['SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM', 'NWCG_REPORTING_AGENCY',\n",
      "       'FIRE_YEAR', 'STAT_CAUSE_CODE', 'LATITUDE', 'LONGITUDE', 'OWNER_CODE',\n",
      "       'STATE', 'DISCOVERY_MONTH', 'DISCOVERY_TOD', 'STATE_PRCNT_FOREST',\n",
      "       'AVG_TEMP', 'AVG_PREC', 'PREDICTED_CLASS', 'Area Range'],\n",
      "      dtype='object')\n",
      "      SOURCE_SYSTEM_TYPE  SOURCE_SYSTEM  NWCG_REPORTING_AGENCY  FIRE_YEAR  \\\n",
      "5010                   0              0                      0       2005   \n",
      "5020                   0              0                      0       2005   \n",
      "\n",
      "      STAT_CAUSE_CODE  LATITUDE  LONGITUDE  OWNER_CODE  STATE  \\\n",
      "5010              1.0      36.5     -112.2         5.0      2   \n",
      "5020              5.0      30.3      -84.4        13.0      9   \n",
      "\n",
      "      DISCOVERY_MONTH  DISCOVERY_TOD  STATE_PRCNT_FOREST  AVG_TEMP  AVG_PREC  \\\n",
      "5010                8              3               25.64      61.1     11.80   \n",
      "5020               11              3               50.68      70.8     54.33   \n",
      "\n",
      "      PREDICTED_CLASS      Area Range  \n",
      "5010                1    0-0.25 acres  \n",
      "5020                2  0.26-9.9 acres  \n"
     ]
    }
   ],
   "source": [
    "function1(dfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vN0JCQlxIRY"
   },
   "source": [
    "Result: 2 columns namely 'PREDICTED_CLASS' and 'Area Range' are the results obtained for the given set of features in our model. \n",
    "We can change the number of input features as per our convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9isRw4kpxafH"
   },
   "outputs": [],
   "source": [
    "#Function 2: Taking both x and y values to get the the Performance Metric values for our given data\n",
    "def function2(dataset):\n",
    "  '''Taking the entire dataset as input for this function and then using the labels to determine MAE and MAPE scores'''\n",
    "  #Encoding y_data for computation purpose\n",
    "  dataset['FIRE_SIZE_CLASS'] = dataset['FIRE_SIZE_CLASS'].map({'A': 1, 'B': 2, 'C':3, 'D':4, 'E': 5, 'F': 6,'G': 7}) \n",
    "  dataset['FIRE_SIZE_CLASS'].astype('int64')\n",
    "\n",
    "  #Breaking down  features and label data \n",
    "  \n",
    "  y_data = dataset['FIRE_SIZE_CLASS']\n",
    "  x_data = dataset.drop(['FIRE_SIZE_CLASS'], axis = 1)\n",
    "  \n",
    "  #Predicing labels using x_data (Similar to function 1)\n",
    "  del_features = ['OBJECTID', 'FOD_ID', 'FPA_ID', 'NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT', 'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID', 'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME', 'ICS_209_INCIDENT_NUMBER' , 'ICS_209_NAME', 'MTBS_FIRE_NAME', 'MTBS_ID', 'COMPLEX_NAME', 'DISCOVERY_DATE', 'STAT_CAUSE_DESCR', 'CONT_DATE', 'CONT_TIME', 'FIRE_SIZE', 'OWNER_DESCR', 'COUNTY', 'FIPS_CODE', 'FIPS_NAME', 'Shape' ]\n",
    "  for i, item in enumerate(del_features):\n",
    "    del x_data[item];\n",
    "\n",
    "\n",
    "  label_encoder = preprocessing.LabelEncoder() \n",
    "  encode_features = ['SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM', 'NWCG_REPORTING_AGENCY']\n",
    "  for j, e_item in enumerate(encode_features):\n",
    "    x_data[e_item] = label_encoder.fit_transform(x_data[e_item]) \n",
    "    x_data[e_item].astype('int64')\n",
    "\n",
    "  #Manually encoding states feature\n",
    "  x_data['STATE'] = x_data['STATE'].map({'AL': 0, 'AK': 1, 'AZ': 2, 'AR': 3, 'CA': 4, 'CO': 5,'CT': 6,'DE': 7,'DC': 8,'FL': 9,'GA': 10,'HI': 11,'ID': 12,'IL': 13,'IN': 14,'IA': 15,'KS': 16,'KY': 17,'LA': 18,'ME': 19,'MD': 20,'MA': 21,'MI': 22,'MN': 23,'MS': 24,'MO': 25,'MT': 26,'NE': 27,'NV': 28,'NH': 29,'NJ': 30,'NM': 31,'NY': 32,'NC': 33,'ND': 34,'OH': 35,'OK': 36,'OR': 37,'PA': 38,'PR': 39,'RI': 40,'SC': 41,'SD': 42,'TN': 43,'TX': 44,'UT': 45,'VT': 46,'VA': 47,'WA': 48,'WV': 49,'WI': 50,'WY': 51}) \n",
    "  x_data['STATE'].astype('int64')\n",
    "\n",
    "  #Adding Feature Discovery Month\n",
    "  discovery_month = [];\n",
    "  for i in range(len(x_data)):\n",
    "   key = x_data.iloc[i]['DISCOVERY_DOY']\n",
    "   if( 1 <= key <= 31 ):\n",
    "    discovery_month.append(1)\n",
    "   elif ( 32 <= key <= 60 ):\n",
    "      discovery_month.append(2)\n",
    "   elif ( 61 <= key <= 91 ):\n",
    "     discovery_month.append(3)\n",
    "   elif ( 92 <= key <= 121 ):\n",
    "     discovery_month.append(4)\n",
    "   elif ( 122 <= key <= 152 ):\n",
    "     discovery_month.append(5)\n",
    "   elif ( 153 <= key <= 182 ):\n",
    "     discovery_month.append(6)\n",
    "   elif ( 183 <= key <= 213 ):\n",
    "     discovery_month.append(7)\n",
    "   elif ( 214 <= key <= 244 ):\n",
    "     discovery_month.append(8)\n",
    "   elif ( 245 <= key <= 274 ):\n",
    "     discovery_month.append(9)\n",
    "   elif ( 275 <= key <= 305 ):\n",
    "     discovery_month.append(10)\n",
    "   elif ( 306 <= key <= 335 ):\n",
    "     discovery_month.append(11)\n",
    "   elif ( 336 <= key <= 366 ):\n",
    "     discovery_month.append(12)\n",
    "    \n",
    "  x_data['DISCOVERY_MONTH'] = discovery_month\n",
    "  x_data['DISCOVERY_MONTH'].astype('int64')\n",
    "\n",
    "  #Delete DISCOVERY_DOY and CONT_DOY also now\n",
    "  del x_data['DISCOVERY_DOY']\n",
    "  del x_data['CONT_DOY']\n",
    "\n",
    "  #Feature2 DISCOVERY_TOD\n",
    "  discovery_tod = [];\n",
    "  x_data['DISCOVERY_TIME'] = x_data['DISCOVERY_TIME'].replace([None],'0000')\n",
    "  for i in range(len(x_data)):\n",
    "    key = x_data.iloc[i]['DISCOVERY_TIME']\n",
    "    if( key == '0000' ):\n",
    "      discovery_tod.append(0)\n",
    "    elif ( '0000' < key <= '0600' ):\n",
    "      discovery_tod.append(1)\n",
    "    elif ( '0600' < key <= '1200' ):\n",
    "      discovery_tod.append(2)\n",
    "    elif ( '1200' < key <= '1600' ):\n",
    "      discovery_tod.append(3)\n",
    "    elif ( '1600' < key <= '2000' ):\n",
    "      discovery_tod.append(4)\n",
    "    elif ( '2000' < key <= '2400' ):\n",
    "      discovery_tod.append(5)\n",
    "\n",
    "  x_data['DISCOVERY_TOD'] = discovery_tod\n",
    "  x_data['DISCOVERY_TOD'].astype('int64')\n",
    "\n",
    "  del x_data['DISCOVERY_TIME']\n",
    "\n",
    "  x_data['LATITUDE'] = (x_data['LATITUDE']*10).apply(np.floor)/10\n",
    "  x_data['LONGITUDE'] = (x_data['LONGITUDE']*10).apply(np.floor)/10\n",
    "\n",
    "  #Add forest Area feature\n",
    "  forest_Area = pd.read_excel('xlsx/FOREST_Area.xlsx')\n",
    "  forest_Area.head()\n",
    "  STATE_PRCNT_FOREST = [];\n",
    "  for i in range(len(x_data)):\n",
    "    key = x_data.iloc[i]['STATE'].astype('int64')\n",
    "    STATE_PRCNT_FOREST.append(forest_Area['Forest_Coverage'].values[key])\n",
    "  \n",
    "  x_data['STATE_PRCNT_FOREST'] = STATE_PRCNT_FOREST\n",
    "  x_data['STATE_PRCNT_FOREST'].astype('float64')\n",
    "\n",
    "  #Add Avg Temp Feature\n",
    "  avg_temp  = pd.read_excel('xlsx/avg_temp.xlsx')\n",
    "\n",
    "  AVG_TEMP_LIST = [];\n",
    "  for i in range(len(x_data)):\n",
    "    state_key = x_data.iloc[i]['STATE'].astype('int64')\n",
    "    year_key = x_data.iloc[i]['FIRE_YEAR'].astype('int64')\n",
    "    AVG_TEMP_LIST.append(avg_temp[year_key].values[state_key])\n",
    "  \n",
    "  x_data['AVG_TEMP'] = AVG_TEMP_LIST\n",
    "  x_data['AVG_TEMP'].astype('float64')\n",
    "\n",
    "  #Add Avg Prec Feature\n",
    "  avg_prec  = pd.read_excel('xlsx/avg_prec.xlsx')\n",
    "\n",
    "  AVG_PREC_LIST = [];\n",
    "  for i in range(len(x_data)):\n",
    "   state_key = x_data.iloc[i]['STATE'].astype('int64')\n",
    "   AVG_PREC_LIST.append(avg_prec['Avg_Prec'].values[state_key])\n",
    "\n",
    "  x_data['AVG_PREC'] = AVG_PREC_LIST\n",
    "  x_data['AVG_PREC'].astype('float64')\n",
    "\n",
    "  predictions = DataPrediction(x_data)\n",
    "\n",
    "  #Got the prediction values, now computing the errors\n",
    "  MAE_value = mean_absolute_error(y_data, predictions)\n",
    "  print('Mean Absolute Error comes out to be: ', MAE_value, '\\n')\n",
    "\n",
    "  y_true, y_pred = np.array(y_data), np.array(predictions)\n",
    "  MAPE_value = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "  print('Mean Absolute Percentage Error is: ', MAPE_value)\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SqqJNao5DhH",
    "outputId": "221f8667-e7b4-4dd3-aee1-218cfd3a48e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRATIK~1\\AppData\\Local\\Temp/ipykernel_16356/4165057873.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['FIRE_SIZE_CLASS'] = dataset['FIRE_SIZE_CLASS'].map({'A': 1, 'B': 2, 'C':3, 'D':4, 'E': 5, 'F': 6,'G': 7})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    0.0s finished\n",
      "Mean Absolute Error comes out to be:  0.508 \n",
      "\n",
      "Mean Absolute Percentage Error is:  23.565079365079363\n"
     ]
    }
   ],
   "source": [
    "function2(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB_SuHVT-Wls"
   },
   "source": [
    "Mean Absolute Percentage Error (MAPE) is the most common error for Forcasting.\n",
    "In our study the MAPE value comes out to be 23.42%\n",
    "which means for the remaining ~ 77% of the times, the model is predicting the right firesize class.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "finalFunctions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
